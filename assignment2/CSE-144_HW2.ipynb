{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d9cc328de632316",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Classification (PyTorch CNN)\n",
    "\n",
    "## Assignment Questions (Follow in Order)\n",
    "\n",
    "- **Q1 (15 pts):** Build the MNIST data pipeline (transforms, train/val split, DataLoaders).\n",
    "- **Q2 (20 pts):** Implement a CNN classifier with the specified architecture.\n",
    "- **Q3 (40 pts):** Implement training and validation functions, run training loop with checkpointing, and plot curves.\n",
    "  - 3.1 (15 pts): Training function\n",
    "  - 3.2 (8 pts): Validation function\n",
    "  - 3.3 (11 pts): Training loop with best checkpoint saving\n",
    "  - 3.4 (6 pts): Plot training and validation curves\n",
    "- **Q4 (5 pts):** Load the best checkpoint and evaluate on the test set.\n",
    "\n",
    "**Total: 80 points**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a0af164edb1ab8",
   "metadata": {},
   "source": [
    "## Starter Notebook (Student Version)\n",
    "\n",
    "Fill in the sections marked with:\n",
    "\n",
    "```python\n",
    "# ========== YOUR CODE STARTS HERE ==========\n",
    "# ========== YOUR CODE ENDS HERE ============\n",
    "```\n",
    "\n",
    "Do **not** change the rubric section above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab5fa7432d125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are running in a fresh environment, uncomment to install dependencies:\n",
    "# !pip -q install torch torchvision matplotlib tqdm scikit-learn\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "device = \"cpu\"  # For fixed, reproducible results. (You may switch to \"cuda\" after you finish debugging.)\n",
    "print(\"device:\", device)\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"Make results as reproducible as possible across runs.\"\"\"\n",
    "    import os, random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    # If you later switch to CUDA and want maximal determinism:\n",
    "    # os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Deterministic flags (safe on CPU; on GPU some ops may error if non-deterministic)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = False\n",
    "    torch.backends.cudnn.allow_tf32 = False\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception as e:\n",
    "        print(\"Warning: could not enable full deterministic algorithms:\", e)\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c660979cc81c216b",
   "metadata": {},
   "source": [
    "## 1. Dataset and DataLoader (15 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41434d30d2c2a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Build the data pipeline\n",
    "data_dir = \"./data\"\n",
    "batch_size = 128  # Use 128 for training\n",
    "num_workers = 0  # For fully reproducible ordering across platforms\n",
    "\n",
    "# ========== YOUR CODE STARTS HERE ==========\n",
    "# TODO:\n",
    "# 1) Create transforms for train and test (normalize with mean=0.1307, std=0.3081)\n",
    "#    Avoid random augmentation for reproducibility\n",
    "# 2) Load MNIST datasets (train and test) using datasets.MNIST()\n",
    "# 3) Split training set into train (55k) and validation (5k) using random_split\n",
    "# 4) Create three DataLoaders (train, val, test)\n",
    "#    For train_loader, use shuffle=True\n",
    "\n",
    "train_tf = None\n",
    "test_tf = None\n",
    "full_train = None\n",
    "test_set = None\n",
    "train_set, val_set = None, None\n",
    "train_loader = None\n",
    "val_loader = None\n",
    "test_loader = None\n",
    "# ========== YOUR CODE ENDS HERE ============\n",
    "\n",
    "print(\"train/val/test:\", len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c458a740bab7c078",
   "metadata": {},
   "source": [
    "## 2. Define the CNN Model (20 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070ff20b212dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: Define your CNN model\n",
    "class MNISTCNN(nn.Module):\n",
    "    \"\"\"Input: (B,1,28,28) -> Output: (B,10)\"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # ========== YOUR CODE STARTS HERE ==========\n",
    "        # Build a CNN with:\n",
    "        # - Feature extraction: 3 convolutional blocks\n",
    "        #   * First block: 1 input channel to 32 output channels, with BatchNorm and ReLU, then MaxPool\n",
    "        #   * Second block: 32 to 64 channels, with BatchNorm and ReLU, then MaxPool\n",
    "        #   * Third block: 64 to 128 channels, with ReLU (no pooling)\n",
    "        #   Use kernel_size=3 and padding=1 for all convolutions, pool_size=2 for pooling\n",
    "        # - Classifier: Flatten, then fully connected layers\n",
    "        #   * After two MaxPool layers, your feature map will be 7x7\n",
    "        #   * First FC layer: 128*7*7 inputs to 256 outputs, with ReLU and Dropout(0.3)\n",
    "        #   * Final FC layer: 256 to num_classes outputs\n",
    "        \n",
    "        self.features = None  # Define your convolutional layers here\n",
    "        self.classifier = None  # Define your fully connected layers here\n",
    "        # ========== YOUR CODE ENDS HERE ============\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ========== YOUR CODE STARTS HERE ==========\n",
    "        # Pass input through features, then classifier\n",
    "        return None\n",
    "        # ========== YOUR CODE ENDS HERE ============\n",
    "\n",
    "model = MNISTCNN().to(device)\n",
    "print(model)\n",
    "\n",
    "# Parameter count\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total params:\", num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3eff8944ce2ef",
   "metadata": {},
   "source": [
    "## 3. Training Loop (40 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oj54273726r",
   "metadata": {},
   "source": [
    "### 3.1 Training Function (15 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1613d92bc1031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.1: Training function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train_one_epoch(model, loader):\n",
    "    \"\"\"Train for one epoch and return (avg_loss, accuracy).\"\"\"\n",
    "    # ========== YOUR CODE STARTS HERE ==========\n",
    "    # TODO:\n",
    "    # - Set model to training mode\n",
    "    # - Loop through batches in the loader\n",
    "    # - For each batch: \n",
    "    #   * Zero gradients\n",
    "    #   * Forward pass\n",
    "    #   * Compute loss\n",
    "    #   * Backward pass\n",
    "    #   * Optimizer step\n",
    "    # - Track total loss and accuracy (IMPORTANT: get predicted labels and compare with targets)\n",
    "    # - Return average loss and accuracy\n",
    "    \n",
    "    return None, None\n",
    "    # ========== YOUR CODE ENDS HERE ============"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xbb8o58tv8m",
   "metadata": {},
   "source": [
    "### 3.2 Validation Function (8 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vkwh1fwshzh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.2: Validation function\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    \"\"\"Evaluate model and return (avg_loss, accuracy).\"\"\"\n",
    "    # ========== YOUR CODE STARTS HERE ==========\n",
    "    # TODO:\n",
    "    # - Set model to evaluation mode\n",
    "    # - Loop through batches without computing gradients\n",
    "    # - Compute loss and accuracy\n",
    "    # - Return average loss and accuracy\n",
    "    \n",
    "    return None, None\n",
    "    # ========== YOUR CODE ENDS HERE ============"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r0lqhs5hh9a",
   "metadata": {},
   "source": [
    "### 3.3 Training Loop (11 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b528eb3e1d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.3: Training loop with checkpointing\n",
    "epochs = 10\n",
    "history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "best_val_acc = 0.0\n",
    "best_epoch = -1\n",
    "ckpt_path = \"./checkpoints/best_mnist_cnn.pt\"\n",
    "os.makedirs(os.path.dirname(ckpt_path), exist_ok=True)\n",
    "\n",
    "# ========== YOUR CODE STARTS HERE ==========\n",
    "# TODO:\n",
    "# - Loop through epochs\n",
    "# - Each epoch: train, validate, log metrics\n",
    "# - Track best validation accuracy and save checkpoint when improved\n",
    "# - Print training and validation metrics each epoch\n",
    "# - For checkpoint: save a dictionary containing keys `model_state_dict` and `epoch`\n",
    "\n",
    "# ========== YOUR CODE ENDS HERE ============\n",
    "\n",
    "print(\"Best val acc:\", best_val_acc, \"at epoch\", best_epoch)\n",
    "print(\"Saved to:\", ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28a920f5b1ab00",
   "metadata": {},
   "source": [
    "### 3.4 Plot Training Curves (6 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d32a8c0538ac8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.4: Plot curves\n",
    "# ========== YOUR CODE STARTS HERE ==========\n",
    "# TODO:\n",
    "# - Create two plots: one for loss (train vs val), one for accuracy (train vs val)\n",
    "# - Use the history dictionary to get the values\n",
    "# - Add labels, legends, and display the plots\n",
    "\n",
    "# ========== YOUR CODE ENDS HERE ============"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b00b1caa261ac1",
   "metadata": {},
   "source": [
    "## 4. Testing (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b3d2e9f080f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Test evaluation\n",
    "# ========== YOUR CODE STARTS HERE ==========\n",
    "# TODO:\n",
    "# - Load the best checkpoint (it's a dictionary with 'model_state_dict' and 'epoch')\n",
    "# - Load the model state from the checkpoint\n",
    "# - Evaluate on the test set\n",
    "# - Print test loss and accuracy\n",
    "\n",
    "test_loss, test_acc = None, None\n",
    "# ========== YOUR CODE ENDS HERE ============\n",
    "\n",
    "print(f\"Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse144",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
